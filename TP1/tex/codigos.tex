\section{Codigos}
\subsection{main.py}
\emph{\color{red} ACTUALIZAR }
\begin{lstlisting}[caption=main.py]
from new_perceptron import perceptron_Multiple,sigmoidea_bipolar,sigmoidea_logistica
from numpy import *
from sklearn.grid_search import ParameterGrid
from pylab import Line2D, plot, axis, show, pcolor, colorbar, bone, savefig
from timeit import default_timer as timer 

import pylab as plt
import sys
import cPickle
import datetime

def imprimirImagen(ejercicio, error_t_hist,error_v_hist, suma, img_name, prnt=False, save=True):
	plt.xlabel('Epoch')
	plt.title("Ejercicio "+str(ejercicio))
	plt.plot(error_t_hist, label="Training")
	if suma:
		img_name += "_sum.png"
		plt.ylabel('Suma de errores')
	else:
		img_name += "_mean.png"
		plt.ylabel('Promedio de errores')
	plt.plot(error_v_hist, label="Validacion")
	plt.grid()
	plt.legend()
	if prnt:
		plt.show()
	if save:
		plt.savefig(img_name)
	plt.close()

def train(ejercicio,Dataset=None, save_file=None, epsilon=0.1, tau=1000, etha=0.01,m=0.6,holdoutRate=0.5, modo=0, 
	early=0,unitsPorCapa=[15], wrapper=False):
	if not wrapper:			
		print "Ejercicio ",ejercicio	
		print "File "+str(Dataset)
		print "Unidades por capa " + str(unitsPorCapa)
		print "Error aceptable " + str(epsilon)
		print "Max Epocas " +str(tau)
		print "Learning Rate " + str(etha)
	Red=perceptron_Multiple(unitsPorCapa,epsilon,tau,etha,m,holdoutRate)
	Red.load_dataset(Dataset, ejercicio)
	i = 1
	best_error = -1
	if wrapper:
		error_t_hist_best = None
		error_v_hist_best = None
		error_v_hist_sum_best = None
		error_t_hist_sum_best = None
		i = 3
	for _ in xrange(i):
		error_t_hist,error_v_hist, error_v_hist_sum, error_t_hist_sum, epoch = Red.train(modo, early)
		if best_error == -1 or (wrapper and error_v_hist_sum[-1] < best_error):
			best_error = error_v_hist_sum[-1]
			error_t_hist_best = error_t_hist
			error_v_hist_best = error_v_hist
			error_v_hist_sum_best = error_v_hist_sum
			error_t_hist_sum_best = error_t_hist_sum
	if not wrapper:
		print '>> epochAlcanzada: ' + str(epoch)
		print '>> error promedio Training:	' + str(error_t_hist_best[-1])
		print '>> error promedio Testing:	' + str(error_v_hist_best[-1])
		print '>> suma de errores Training:	' + str(error_t_hist_sum_best[-1])
		print '>> suma de errores Testing:	' + str(error_v_hist_sum_best[-1])	
	img_name= "ej"+str(ejercicio)+"_"+str(etha)+"_"+str(m)+"_"+str(modo)+"_"+str(unitsPorCapa)	
	imprimirImagen(ejercicio, error_t_hist_best,error_v_hist_best, suma=False, img_name=img_name)
	imprimirImagen(ejercicio, error_v_hist_sum_best, error_t_hist_sum_best, suma=True, img_name=img_name)
	
	if(save_file!=None):
		print "Guardando Red"
		with open(save_file, "wb") as output:
			cPickle.dump(Red, output, cPickle.HIGHEST_PROTOCOL)
	return error_t_hist_sum[-1], error_v_hist_sum[-1]

def load(ej,Net,Dataset, prnt=True):
	print "Cargando Red tipo Ejercicio ",ej
	with open(Net, "rb") as input:
		Red = cPickle.load(input) # protocol version is auto detected
	Red.load_dataset(Dataset, ej)
	lista_error,errorTotal,cantidad_errores = Red.evaluate()
	print '>> error total acumulado: ' + str(errorTotal)+' Numero de equivocaciones: '+str(cantidad_errores)	
	plt.plot(lista_error)
	plt.ylabel('Valor del error')
	if prnt:
		plt.show()
	return errorTotal, cantidad_errores	

def grid_search(param_grid):
	grid = ParameterGrid(param_grid)
	best_error = None
	best_params = None
	print "Ejercicio "+str(param_grid["1"])
	print len(grid), "modelos distintos"
	i = 0
	print "i 	error(training, validacion)"
	start = timer()
	for params in grid:
	    e = train(params['1'], params['2'], params['3'],params['4'],params['5'],params['6'],params['7'],params['8'],
	    	params['9'], params['10'],params['11'], True )
	    print i, "	", e
	    i += 1
	    if i%50 == 0:
	    	end = timer()
	    	print int((end-start)/60), " min"
	    if best_error == None or e < best_error:
	    	best_error = e
	    	best_params = [params['1'], params['2'], params['3'],params['4'],params['5'],params['6'],params['7'],params['8'],
	    	params['9'], 	params['10'],params['11']]
	print "MEJOR ERROR Y MODELO EJERCICIO "+str(param_grid["1"])
	print "training, validacion:", best_error
	print "parametros:", best_params
	end = timer()
	print int((end-start)/60), " min"
	
args = sys.argv
message = "\nModo de uso:\n\
python main.py (ej1|ej2) -t nomDataSet nomFfileout parametros\n\
Con los siguientes parametros en orden:\n\
epsilon tau etha momentum holdoutRate modo_aprendizaje\n\n\
-t es para entrenar\
-l es para testear\
modo_aprendizaje = 0 para batch 1 para incremental\
"

# print len(args)
if len(args)==1:
	pruebas()
	sys.exit()
elif len(args) < 5:
	print message
	sys.exit()

cmdTrain = args[2] == "-t"
cmdLoad = args[2] == "-l"

if(args[1] == "ej1"):
	ejercicio=1
elif(args[1] == "ej2"):
	ejercicio=2
else:
	print message
	sys.exit()

if cmdTrain:
	
	if len(args) < 3:
		print "\nIncorrecta cantidad de argumentos para entrenar."
		print message
		sys.exit()
	archivoDataset = args[3]
	archivoRed=None
	errorAceptable=0.1
	maxEpoch=1000
	learningRate=0.01
	momentum=0.6
	holdoutRate=0.5
	modo=0
	early=0
	unitsPorCapa=[5]
	if len(args) > 4:
		archivoRed=args[4]
	if len(args) > 5:
		errorAceptable = float(args[5])
	if len(args) > 6:
		maxEpoch = int(args[6])
	if len(args) > 7:
		learningRate = float(args[7])
	if len(args) > 8:
		momentum = float(args[8])
	if len(args) > 9:
		holdoutRate = float(args[9])
	if len(args) > 10:
		modo=int(args[10])
	if len(args) > 11:
		early=int(args[11])
	if len(args) > 12:
		#unitsPorCapa=int(args[11])
		str1=str(args[12])
		unitsPorCapa=map(int, str1[1:-1].split(','))
	train(ejercicio,archivoDataset,archivoRed,errorAceptable,maxEpoch,learningRate,momentum,holdoutRate,modo, early,
	 unitsPorCapa)

elif cmdLoad:
	
	if len(args) != 5:
		print "\nIncorrecta cantidad de argumentos para entrenar."
		print message
		sys.exit()
		
	archivoRed = args[3]
	archivoDataset = args[4]
	
	load(ejercicio,archivoRed, archivoDataset)
else:
	print message
\end{lstlisting}


\subsection{new\_perceptron.py}

\begin{lstlisting}[caption=new\_perceptron.py]
from numpy import *
import math
def sigmoidea_bipolar(vector, derivative=False):
	B = 1
	if derivative:
		return B * (1 -sigmoidea_bipolar(vector)**2)
	else:
		return tanh(B*vector)

def sigmoidea_logistica(vector, derivative=False):
	B = 1
	if derivative:
		return B * (1 -sigmoidea_logistica(vector))*sigmoidea_logistica(vector)
	else:
		return 1/(1+exp(-vector))

class perceptron_Multiple:

	def load_dataset(self,dataset, ejercicio):
		# print "> Cargando dataset..."	
		f = open(dataset)
		self.X = []
		self.Z = []
		for line in f:
			if line.rstrip():
				if ejercicio == 1:
					r = line.rstrip().split(", ")
					x_i = map(float, r[1:])
					z_i = map(self.cod, r[0])
				else:
					r = line.rstrip().split(",	")
					x_i = map(float, r[:-2])
					z_i = map(float, r[-2:])
				self.X.append(x_i)
				self.Z.append(z_i)
		self.normalizar(self.X)
		if ejercicio != 1:
			self.normalizar(self.Z)
		self.X = array(self.X) # Para pretty print
		self.Z = array(self.Z)

	def __init__(self,UnitsXCapa=[15],e=0,t=0,nl=0,m=0.6,holdout=1,funcionActivacion=sigmoidea_bipolar):
		self.funcActivacion = funcionActivacion	
		self.epsilon = e
		self.tau = t
		self.eta = nl
		self.p = holdout
		self.momentum = m
	 	# CANT CAPAS
	 	self.L=len(UnitsXCapa)+2
	 	self.UnitsXCapa=UnitsXCapa
	 	self.Beta=1

	def cod(self,c):
		if c == "M":
			return 1
		else:
			return -1 

	def normalizar(self, array):
		media = mean(array, axis= 0) 
		varianza = std(array, axis=0)
		for i in xrange(len(array)):
			array[i] = (array[i] - media )/varianza	

	def train(self,modo=0, early=0):
		self.P = len(self.X)
		self.S = [shape(self.X)[1]]
		self.S.extend(self.UnitsXCapa)
		self.S.append(shape(self.Z)[1])
		self.S = array(self.S)
		# TAMANOS W, dW, Y
		# Basura en la pos 0, indizado desde 1
		self.W = array([random.uniform(-sqrt(self.S[j]),sqrt(self.S[j]), (self.S[j-1]+1, self.S[j])) for j in range(self.L)])
		# Basura en la pos 0, indizado desde 1
		self.dW = array([zeros((self.S[j-1]+1, self.S[j])) for j in range(self.L)])
		self.Y = [zeros((1, self.S[j]+1)) for j in range(self.L-1)]
		self.Y.append([zeros((1,shape(self.Z)[1]))])
		t,error_v_hist,error_t_hist, error_t_hist_sum, error_v_hist_sum = self.holdout(self.epsilon, self.tau, self.p, modo, early)
		# print error_t_hist[-1],error_v_hist[-1] ,t 
		return error_t_hist,error_v_hist, error_v_hist_sum, error_t_hist_sum, t

	def holdout(self,epsilon, tau, p, modo, early):
		e_t = 1
		e_v = 1
		t = 0
		v = int(p*self.P)
		error_v_hist=[]
		error_t_hist=[]
		error_v_hist_sum=[]
		error_t_hist_sum=[]
		early_count = 0
		while(t<self.tau and e_t > self.epsilon):
			# if t == 0 and modo:
			# 	print "Modo incremental"
			# elif t == 0 and not modo:
			# 	print "Modo batch"			
			e_t, e_t_sum = self.training(self.X[:v],self.Z[:v], modo)
			e_v, e_v_sum = self.testing(self.X[v:],self.Z[v:])
			error_v_hist.append(e_v)
			error_t_hist.append(e_t)
			error_v_hist_sum.append(e_v_sum)
			error_t_hist_sum.append(e_t_sum)
			t += 1
			#early_count = (early_count+1) if t > 2 and error_v_hist[-1]>error_v_hist[-2] else 0
			# if(t % 10==1):
			# 	print "epoch", t, "   e_training", e_t, "	e_validation", e_v
			# if early and early_count>=30:
			# 	print "Early Stopping - 30 epochs de crecimiento de error de validacion"
			# 	break
		return t,error_v_hist,error_t_hist, error_t_hist_sum, error_v_hist_sum

	def training(self,X, Z, modo):
		e_count = 0
		e_sum = 0
		for h in range(len(X)): 
			self.activation(X[h])
			e = self.correction(Z[h])
			if e > self.epsilon:
				e_count += 1
			e_sum += e
			if modo:
				self.adaptation()
		if not modo:
			self.adaptation()	
		return e_sum/(len(X) if len(X) != 0 else 1), e_count

	def activation(self,X_h):
		self.Y[0] = append(X_h, [-1])[newaxis]
		for j in range(1, self.L):
			if j == self.L-1:
				self.Y[j] = self.funcActivacion(dot(self.Y[j-1], self.W[j]))
			else:
				self.Y[j] = append(self.funcActivacion(dot(self.Y[j-1], self.W[j])), [-1])[newaxis]
		return self.Y[-1]

	def correction(self,Z_h):
		E = Z_h - self.Y[-1]
		e = (E**2).sum()
		for j in range(self.L-1, 0, -1):   
			D = E*self.funcActivacion(dot(self.Y[j-1], self.W[j]), True)
			self.dW[j] += (self.eta*dot(transpose(self.Y[j-1]), D)) 
			# El error no tiene sentido q tenga el -1 del final
			E = dot(D, transpose(self.W[j]))[0][:-1]
		return e

	def adaptation(self):
		for j in range(1, self.L):
			self.W[j] += self.dW[j] 
			self.dW[j] *= self.momentum

	def testing(self,X, Z):
		e_count = 0
		e_sum = 0
		for (X_h, Z_h) in zip(X, Z):
			E = self.activation(X_h)-Z_h
			e = (E**2).sum()
			if e > self.epsilon:
				e_count += 1
			e_sum += e
		return e_sum/(len(X) if len(X) != 0 else 1), e_count

	def evaluate(self):	
		e_sum = 0
		list_error=[]
		numero_error=0
		for (X_h, Z_h) in zip(self.X, self.Z):
			E=self.activation(X_h)-Z_h
			if((E**2).sum()>=1):
				numero_error+=1
			e_sum+=(E**2).sum()
			list_error.append((E**2).sum())
		return list_error,e_sum/(len(self.X) if len(self.X) != 0 else 1),numero_error	



\end{lstlisting}
